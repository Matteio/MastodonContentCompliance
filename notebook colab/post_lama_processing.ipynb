{"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyML1DjynvUMn9A08Tx/vxFB","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8819968,"sourceType":"datasetVersion","datasetId":5306056}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/NicolaGabriele/MastodonContentCompliance/blob/main/post_ollama_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"import requests\nimport json\nimport os\nimport time\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-07-01T13:22:52.785525Z","iopub.execute_input":"2024-07-01T13:22:52.785869Z","iopub.status.idle":"2024-07-01T13:22:52.795313Z","shell.execute_reply.started":"2024-07-01T13:22:52.785845Z","shell.execute_reply":"2024-07-01T13:22:52.794469Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#istallazione di ollama\n!curl -fsSL https://ollama.com/install.sh | sh","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wkDuXLuzUk1K","outputId":"09da6314-1017-4217-c391-6ee81bdeca7d","scrolled":true,"execution":{"iopub.status.busy":"2024-07-01T13:36:21.959487Z","iopub.execute_input":"2024-07-01T13:36:21.960368Z","iopub.status.idle":"2024-07-01T13:36:25.466210Z","shell.execute_reply.started":"2024-07-01T13:36:21.960335Z","shell.execute_reply":"2024-07-01T13:36:25.465235Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":">>> Downloading ollama...\n######################################################################## 100.0%#=#=#                                                                          \n>>> Installing ollama to /usr/local/bin...\n>>> Adding ollama user to video group...\n>>> Adding current user to ollama group...\n>>> Creating ollama systemd service...\n>>> NVIDIA GPU installed.\n>>> The Ollama API is now available at 127.0.0.1:11434.\n>>> Install complete. Run \"ollama\" from the command line.\n","output_type":"stream"}]},{"cell_type":"code","source":"#un thread demone avvia il server locale di ollama\nimport subprocess\nimport threading\nt = threading.Thread(target=lambda: subprocess.run([\"ollama\", \"serve\"]),daemon=True)\nt.start()","metadata":{"id":"c43LDFSFUqfY","execution":{"iopub.status.busy":"2024-07-01T13:52:14.221096Z","iopub.execute_input":"2024-07-01T13:52:14.221919Z","iopub.status.idle":"2024-07-01T13:52:14.231397Z","shell.execute_reply.started":"2024-07-01T13:52:14.221885Z","shell.execute_reply":"2024-07-01T13:52:14.230170Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Error: listen tcp 127.0.0.1:11434: bind: address already in use\n","output_type":"stream"}]},{"cell_type":"code","source":"#un altro thread demone avvia llama3\n!ollama pull llama3\nt2 = threading.Thread(target=lambda: subprocess.run([\"ollama\", \"run\", \"llama3\"]),daemon=True)\nt2.start()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9MQMgyp9U0hL","outputId":"fd6addf1-d873-498d-f0e6-8dea75381e7e","scrolled":true,"execution":{"iopub.status.busy":"2024-07-01T13:52:14.559991Z","iopub.execute_input":"2024-07-01T13:52:14.560322Z","iopub.status.idle":"2024-07-01T13:52:16.063158Z","shell.execute_reply.started":"2024-07-01T13:52:14.560295Z","shell.execute_reply":"2024-07-01T13:52:16.061988Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"[GIN] 2024/07/01 - 13:52:15 | 200 |      26.309µs |       127.0.0.1 | HEAD     \"/\"\n\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h[GIN] 2024/07/01 - 13:52:15 | 200 |  538.759769ms |       127.0.0.1 | POST     \"/api/pull\"\n\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \npulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB                         \npulling 4fa551d4f938... 100% ▕████████████████▏  12 KB                         \npulling 8ab4849b038c... 100% ▕████████████████▏  254 B                         \npulling 577073ffcc6c... 100% ▕████████████████▏  110 B                         \npulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B                         \nverifying sha256 digest \nwriting manifest \nremoving any unused layers \nsuccess \u001b[?25h\n","output_type":"stream"}]},{"cell_type":"code","source":"moderator_instructions = [\n'You are a decentralized social-network instance\\'s moderator. Your role is to check if utent\\'s post respects the instance rules. You must assign each post a score from 0 (if the post violate completely the instance\\'s rules) to 10 (if the post respects all the instance\\'s rules). Your response must be only the score number and anything else.' ,\n'You are a decentralized social-network instance\\'s owner. Your role is to check if utent\\'s post respects the instance rules. In order to classify posts you have to assign each post a score from 0(if the post violate completely the instance\\'s rules) to 10(if the post respects all the instance\\'s rules). You must be very strict in your evaluations. Please pay a lot of attention and let\\'s think step by step. Your response must be only the score number and anything else.'\n]\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T13:52:16.065854Z","iopub.execute_input":"2024-07-01T13:52:16.066891Z","iopub.status.idle":"2024-07-01T13:52:16.072480Z","shell.execute_reply.started":"2024-07-01T13:52:16.066851Z","shell.execute_reply":"2024-07-01T13:52:16.071517Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def ask_to_llama(instruction,rules, prompt):    \n    full_context = instruction\n    for i, rule in enumerate(rules, start=1):\n        full_context += f\"{i}. {rule['text']}\\n\"\n    \n    full_prompt = full_context + prompt\n    \n    response = requests.post('http://localhost:11434/api/generate', \n                             data=json.dumps({'model': 'llama3', 'prompt': full_prompt, 'stream': False}), \n                             headers={'Content-Type': 'application/json'})\n    \n    return response.json()['response']","metadata":{"execution":{"iopub.status.busy":"2024-07-01T13:52:16.073663Z","iopub.execute_input":"2024-07-01T13:52:16.074001Z","iopub.status.idle":"2024-07-01T13:52:16.085784Z","shell.execute_reply.started":"2024-07-01T13:52:16.073969Z","shell.execute_reply":"2024-07-01T13:52:16.084775Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"[GIN] 2024/07/01 - 13:52:16 | 200 |      31.723µs |       127.0.0.1 | HEAD     \"/\"\n[GIN] 2024/07/01 - 13:52:16 | 200 |   25.887782ms |       127.0.0.1 | POST     \"/api/show\"\n[GIN] 2024/07/01 - 13:52:16 | 200 |    1.284151ms |       127.0.0.1 | POST     \"/api/generate\"\n","output_type":"stream"},{"name":"stderr","text":"\u001b[?25l\u001b[?25l\u001b[?25h\u001b[2K\u001b[1G\u001b[?25h\u001b[?25l\u001b[?25h","output_type":"stream"}]},{"cell_type":"code","source":"def process_json_files(instances, start, end, save_dir):\n    \n    start_time = time.time()\n    istanze = os.listdir(instances)\n    \n    \n    for i in tqdm(range(start, end)):\n        filename = istanze[i]\n        if filename.endswith('.json'):\n            filepath = os.path.join(instances, filename)\n            with open(filepath, 'r') as file:\n                data = json.load(file)\n                instance_name = data['name']\n                results = {'name': instance_name, 'rules': data['rules'], 'records':[]}\n                rules = data['rules']\n                records = data['records']\n                records_en = [record for record in records if record['language'] == 'en']\n                        \n                if len(records_en)==0:\n                    print(f\"Per l'istanza {instance_name} non ci sono post in inglese\")\n                    filt_recorods = []\n                    \n                if len(records_en)>200: #se len>200 prendiamo solo testa e coda\n                    records_ordinati = sorted(records_en, key=lambda x: x['favourites'])\n                    primi_100 = records_ordinati[:100]\n                    ultimi_100 = records_ordinati[-100:]\n                    filt_records = primi_100 + ultimi_100\n                    \n                else: #altrimenti li prendiamo tutti\n                    filt_records = records_en\n                \n                print(\"Numero di post: \",len(filt_records))\n                i=0\n                for record in filt_records:\n                    record_text = record['text']\n                    rec = {'id': record['id'], 'text': record_text, 'tests':[]}\n                    i+=1\n                    for instruction in moderator_instructions:\n                        response = ask_to_llama(instruction,rules,record_text)\n                        rec['tests'].append({'instruction': instruction, 'score': response})\n                        #break #così vediamo cosa fa con le altre instanze\n                    results['records'].append(rec)\n                    print(f\"Processati {i} post\")\n                print(f'instance {instance_name} successfully processed\\n')\n                if not os.path.isdir(save_dir):\n                    os.mkdir(save_dir)\n                with open(os.path.join(save_dir, f'{instance_name}_scores.json'),'w') as f:\n                    json.dump(results, f)\n                    #break \n        break\n    end_time = time.time() \n    duration = end_time - start_time\n    print(\"DURATA: \", duration)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T13:52:19.715985Z","iopub.execute_input":"2024-07-01T13:52:19.716806Z","iopub.status.idle":"2024-07-01T13:52:19.729923Z","shell.execute_reply.started":"2024-07-01T13:52:19.716774Z","shell.execute_reply":"2024-07-01T13:52:19.728998Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"instances = '/kaggle/input/instance-json/results'\nprocess_json_files(instances,0,1,'/kaggle/working/')\n#len(os.listdir(instances))//num_profili\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-01T13:52:20.414042Z","iopub.execute_input":"2024-07-01T13:52:20.414822Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 0/1 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Numero di post:  200\n[GIN] 2024/07/01 - 13:52:23 | 200 |  2.218799042s |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/07/01 - 13:52:25 | 200 |  2.199394864s |       127.0.0.1 | POST     \"/api/generate\"\nProcessati 1 post\n[GIN] 2024/07/01 - 13:52:27 | 200 |  2.232819551s |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/07/01 - 13:52:30 | 200 |  2.241168502s |       127.0.0.1 | POST     \"/api/generate\"\nProcessati 2 post\n[GIN] 2024/07/01 - 13:52:32 | 200 |  2.234079957s |       127.0.0.1 | POST     \"/api/generate\"\n[GIN] 2024/07/01 - 13:52:34 | 200 |   2.24006156s |       127.0.0.1 | POST     \"/api/generate\"\nProcessati 3 post\n[GIN] 2024/07/01 - 13:52:36 | 200 |  2.232627115s |       127.0.0.1 | POST     \"/api/generate\"\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install bertopic","metadata":{},"execution_count":null,"outputs":[]}]}